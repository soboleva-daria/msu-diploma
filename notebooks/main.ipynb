{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from copy import copy\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '../code/venv')\n",
    "from qa_system import QuestionAnswerSystem\n",
    "from utils import Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/train_task_b.csv')\n",
    "df = df.set_index('question_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем БД"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qa_system = QuestionAnswerSystem()\n",
    "qa_system.create_database(df)\n",
    "qa_system.add_database_to_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Переводим вопрос и ответ в лемматизированную форму"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50364 [00:00<?, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "50365it [01:35, 528.18it/s]                           \n",
      "100%|██████████| 50365/50365 [00:45<00:00, 1115.87it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm_pandas(tqdm(total=df.index.nunique()))\n",
    "df['question_lem'] = df.groupby('question_id').progress_apply(lambda x: Utility.lemmatize_question(x.question.values[0]))\n",
    "df['answer_lem'] = df.groupby('question_id').progress_apply(lambda x: Utility.lemmatize(x.answer.values[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выбираем лучший алгоритм поиска релевантного документа на подвыборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sample = df.sample(frac=0.01, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 504/504 [00:54<00:00,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25F: Accuracy: 0.9761904761904762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Freq: 0.66\n",
    "## Tf-idf: 0.88\n",
    "## Bm25f: 0.9688\n",
    "## MAX_INTERSECT_DOC: 0.76\n",
    "\n",
    "search_rel_question_doc_alg_str = \"BM25F\"\n",
    "qa_system = QuestionAnswerSystem(search_rel_question_doc_alg_str)\n",
    "\n",
    "accuracy = 0\n",
    "errors = {}\n",
    "for question_lem, paragraph_id, question_id in tqdm(df_sample.reset_index()[['question_lem', 'paragraph_id', 'question_id']].values, total=df_sample.question.nunique()):\n",
    "    doc_ids = qa_system.find_rel_question_doc_ids(question_str_lem=question_lem)\n",
    "    if paragraph_id in doc_ids:\n",
    "        accuracy += 1\n",
    "    else:\n",
    "        errors[question_id] = copy(doc_ids)\n",
    "\n",
    "print('{}: Accuracy: {}'.format(search_rel_question_doc_alg_str, accuracy/df_sample.question.nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Для лучшего алгоритма делаем пересчет по всей коллекции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50364it [1:33:29,  8.98it/s]                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25F: Accuracy: 0.9726971267449018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "search_rel_question_doc_alg_str = \"BM25F\"\n",
    "if not os.path.exists(search_rel_question_doc_alg_str):\n",
    "    os.mkdir(search_rel_question_doc_alg_str)\n",
    "qa_system = QuestionAnswerSystem(search_rel_question_doc_alg_str) \n",
    "\n",
    "accuracy = 0\n",
    "errors = {}\n",
    "for question_lem, paragraph_id, question_id in tqdm(df.reset_index()[['question_lem', 'paragraph_id', 'question_id']].values, total=df.question.nunique()):\n",
    "    doc_ids = qa_system.find_rel_question_doc_ids(question_str_lem=question_lem)\n",
    "    if paragraph_id in doc_ids:\n",
    "        accuracy += 1\n",
    "    else:\n",
    "        errors[question_id] = doc_ids\n",
    "    np.save('{}/{}.npy'.format(search_rel_question_doc_alg_str, question_id), doc_ids)\n",
    "np.save('{}_interrogative_pronouns_errors.npy'.format(search_rel_question_doc_alg_str), errors)\n",
    "print('{}: Accuracy: {}'.format(search_rel_question_doc_alg_str, accuracy/df.question.nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формируем датасет для обучения (этап 2)\n",
    "## Не учитываем те вопросы, по которым ошиблись на этапе 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50364/50364 [03:15<00:00, 257.87it/s]\n",
      "  0%|          | 0/2718499 [00:00<?, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "100%|██████████| 2718499/2718499 [2:30:25<00:00, 301.20it/s]  \n"
     ]
    }
   ],
   "source": [
    "search_rel_question_doc_alg_str = 'BM25F'\n",
    "errors = np.load('{}_interrogative_pronouns_errors.npy'.format(search_rel_question_doc_alg_str)).item()\n",
    "train_df = QuestionAnswerSystem.create_train_dataset(errors=errors)\n",
    "\n",
    "tqdm_pandas(tqdm(total=train_df.shape[0]))\n",
    "train_df['sentence_lem'] = train_df.progress_apply(lambda x: Utility.lemmatize(x.sentence), axis=1)\n",
    "train_df.to_pickle('train_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Делаем разметку для классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2718499/2718499 [04:32<00:00, 9986.65it/s] \n"
     ]
    }
   ],
   "source": [
    "train_df = pd.merge(train_df, df.reset_index()[['question_id', 'question', 'question_lem', 'answer', 'answer_lem']], how='left', on='question_id')\n",
    "train_df_with_target = QuestionAnswerSystem.create_target(train_df)\n",
    "train_df_with_target.to_pickle('train_df_with_target.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фильтруем датасет по наличию хотя бы одного предложения с ответом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daria_soboleva/anaconda3/envs/icutestenv/lib/python3.5/site-packages/ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_df_with_target = train_df_with_target.set_index('question_id')\n",
    "train_df_with_target = train_df_with_target[train_df_with_target.groupby('question_id').apply(lambda x: any(x.answer_in_sentence == 1))]\n",
    "train_df_with_target.to_pickle('train_df_with_target_filtered.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Этап 2. Построение классификатора Ans_in_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4% вопросов отсеялись на этапе 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('train_df_with_target_filtered.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df_idxs, test_df_idxs = Utility.train_test_split(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Базовые статистики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/48238 [00:00<?, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "48239it [50:52, 15.80it/s]                             \n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('idfs.pickle', 'rb' ) as f:\n",
    "    idfs = pickle.load(f)\n",
    "with open('idfs_lema.pickle', 'rb' ) as f:\n",
    "    idfs_lem = pickle.load(f)\n",
    "    \n",
    "tqdm_pandas(tqdm(total=df.index.nunique()))\n",
    "base_stats = df.groupby('question_id').progress_apply(lambda x: \n",
    "                                                     QuestionAnswerSystem.get_base_stats(\n",
    "                                                         x.question.values[0],\n",
    "                                                         list(x.sentence),\n",
    "                                                         x.question_lem.values[0],\n",
    "                                                         list(x.sentence_lem)\n",
    "                                                     )).reset_index()\n",
    "base_stats.drop('level_1', axis=1, inplace=True)\n",
    "base_stats.columns = [\n",
    "    'question_id',\n",
    "    'unique_word_count_score',\n",
    "    'unique_lem_word_count_score',\n",
    "    \n",
    "    'unique_word_percent_score',\n",
    "    'unique_lem_word_percent_score',\n",
    "    \n",
    "    'sentence_len',\n",
    "    'sentence_lem_len',\n",
    "    \n",
    "    'bm25f_score',\n",
    "    'bm25f_lem_score',\n",
    "    \n",
    "    'tf_idf_score',\n",
    "    'tf_idf_lem_score',\n",
    "    \n",
    "    'sentence',\n",
    "    'sentence_lem'\n",
    "]\n",
    "base_stats.drop('sentence_lem', inplace=True, axis=1)\n",
    "base_stats.to_pickle('base_stats.pkl')\n",
    "df = pd.merge(df.reset_index(), base_stats, how='left', on=('question_id', 'sentence')).set_index('question_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Бейзлайны:\n",
    "* max_unique_word_count_score\n",
    "* max_unique_word_percent_score\n",
    "* max_tf_idf_score\n",
    "* max_bm25f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/33767 [00:00<?, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "33768it [00:40, 830.47it/s]                           \n",
      "100%|██████████| 33768/33768 [00:44<00:00, 764.89it/s]\n",
      "100%|██████████| 33768/33768 [00:38<00:00, 883.93it/s] \n",
      "100%|██████████| 33768/33768 [00:39<00:00, 863.71it/s] \n",
      "100%|██████████| 33768/33768 [00:37<00:00, 905.36it/s] \n",
      "100%|██████████| 33768/33768 [00:35<00:00, 953.73it/s] \n",
      "100%|██████████| 33768/33768 [00:37<00:00, 907.91it/s] \n",
      "100%|██████████| 33768/33768 [00:36<00:00, 913.67it/s] \n",
      "  0%|          | 0/14471 [00:00<?, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "14472it [00:15, 927.18it/s]                           \n",
      "100%|██████████| 14472/14472 [00:15<00:00, 939.97it/s] \n",
      "100%|██████████| 14472/14472 [00:14<00:00, 981.02it/s] \n",
      "100%|██████████| 14472/14472 [00:14<00:00, 993.37it/s] \n",
      "100%|██████████| 14472/14472 [00:15<00:00, 911.01it/s] \n",
      "100%|██████████| 14472/14472 [00:19<00:00, 727.57it/s]\n",
      "100%|██████████| 14472/14472 [00:16<00:00, 871.89it/s]\n",
      "100%|██████████| 14472/14472 [00:15<00:00, 957.21it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bm25f_lem_score</th>\n",
       "      <th>bm25f_score</th>\n",
       "      <th>tf_idf_lem_score</th>\n",
       "      <th>tf_idf_score</th>\n",
       "      <th>unique_lem_word_count_score</th>\n",
       "      <th>unique_lem_word_percent_score</th>\n",
       "      <th>unique_word_count_score</th>\n",
       "      <th>unique_word_percent_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.744524</td>\n",
       "      <td>0.693870</td>\n",
       "      <td>0.637758</td>\n",
       "      <td>0.678460</td>\n",
       "      <td>0.776726</td>\n",
       "      <td>0.776726</td>\n",
       "      <td>0.746666</td>\n",
       "      <td>0.746666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>0.748186</td>\n",
       "      <td>0.703468</td>\n",
       "      <td>0.641869</td>\n",
       "      <td>0.685107</td>\n",
       "      <td>0.780200</td>\n",
       "      <td>0.780200</td>\n",
       "      <td>0.749104</td>\n",
       "      <td>0.749104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bm25f_lem_score  bm25f_score  tf_idf_lem_score  tf_idf_score  \\\n",
       "Test          0.744524     0.693870          0.637758      0.678460   \n",
       "Train         0.748186     0.703468          0.641869      0.685107   \n",
       "\n",
       "       unique_lem_word_count_score  unique_lem_word_percent_score  \\\n",
       "Test                      0.776726                       0.776726   \n",
       "Train                     0.780200                       0.780200   \n",
       "\n",
       "       unique_word_count_score  unique_word_percent_score  \n",
       "Test                  0.746666                   0.746666  \n",
       "Train                 0.749104                   0.749104  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_scores(df, columns):\n",
    "    n_questions = df.index.nunique()\n",
    "    scores = {}\n",
    "    tqdm_pandas(tqdm(total=n_questions))\n",
    "    for col in columns:\n",
    "        scores[col] = df.groupby('question_id').progress_apply(lambda x: Utility.get_answer_by_score(x, col)).sum()/n_questions\n",
    "    return scores\n",
    "\n",
    "train_scores = get_scores(df.loc[train_df_idxs], base_stats_new.columns.difference(['question_id', 'sentence_len', 'sentence_lem_len', 'sentence']))\n",
    "test_scores = get_scores(df.loc[test_df_idxs], base_stats_new.columns.difference(['question_id', 'sentence_len', 'sentence_lem_len', 'sentence']))\n",
    "\n",
    "scores = {'Train': {}, 'Test': {}}\n",
    "scores['Train'] = train_scores\n",
    "scores['Test'] = test_scores\n",
    "pd.DataFrame(scores).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('train_df_with_target_filtered.pkl')\n",
    "train_df_idxs, test_df_idxs = Utility.train_test_split(df)\n",
    "\n",
    "base_stats = pd.read_pickle('base_stats.pkl')\n",
    "base_stats.drop('tf_idf_score', axis=1, inplace=True)\n",
    "base_stats.drop('tf_idf_lem_score', axis=1, inplace=True)\n",
    "\n",
    "base_stats_new = pd.read_pickle('tf_idf_bm25f_stats.pkl')\n",
    "base_stats = pd.merge(base_stats, base_stats_new, how='left', on=('question_id', 'sentence'))\n",
    "\n",
    "df = pd.merge(df.reset_index(), base_stats, how='left', on=('question_id', 'sentence')).set_index('question_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лог-регрессия на базовых фичах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/33767 [00:00<?, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "33768it [01:42, 329.75it/s]                           \n",
      "  0%|          | 0/14471 [00:00<?, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "14472it [00:39, 363.30it/s]                           \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Test': 0.81749706309170067, 'Train': 0.82423668078301304}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'answer_in_sentence'\n",
    "predictors = df.columns.difference([\n",
    "    'sentence',\n",
    "    'sentence_lem',\n",
    "    'question',\n",
    "    'question_lem',\n",
    "    'answer',\n",
    "    'answer_lem',\n",
    "    target\n",
    "])\n",
    "df_train = df.loc[train_df_idxs].copy()\n",
    "df_test = df.loc[test_df_idxs].copy()\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(df_train[predictors])\n",
    "X_test_sc = sc.transform(df_test[predictors])\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_sc, df_train[target])\n",
    "\n",
    "df_train['train_predict_proba'] = clf.predict_proba(X_train_sc)[:, 1]\n",
    "df_test['test_predict_proba'] = clf.predict_proba(X_test_sc)[:, 1]\n",
    "\n",
    "tqdm_pandas(tqdm(total=df_train.index.nunique()))\n",
    "train_score = df_train.groupby('question_id').progress_apply(lambda x: Utility.get_answer_by_score(x, 'train_predict_proba')).sum()/df_train.index.nunique()\n",
    "\n",
    "tqdm_pandas(tqdm(total=df_test.index.nunique()))\n",
    "test_score = df_test.groupby('question_id').progress_apply(lambda x: Utility.get_answer_by_score(x, 'test_predict_proba')).sum()/df_test.index.nunique()\n",
    "\n",
    "scores = {'Train': train_score, 'Test': test_score}\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/33767 [00:00<?, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "33768it [00:46, 726.00it/s]                           \n",
      "  0%|          | 0/14471 [00:00<?, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "14472it [00:19, 739.02it/s]                           \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Test': 0.8253748877064474, 'Train': 0.82802736399443244}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = lgb.LGBMClassifier(n_estimators=300, learning_rate=0.1, max_depth=3, min_child_samples=1000, n_jobs=-1)\n",
    "clf.fit(df_train[predictors], df_train[target])\n",
    "\n",
    "df_train['train_predict_proba'] = clf.predict_proba(df_train[predictors])[:, 1]\n",
    "df_test['test_predict_proba'] = clf.predict_proba(df_test[predictors])[:, 1]\n",
    "\n",
    "tqdm_pandas(tqdm(total=df_train.index.nunique()))\n",
    "train_score = df_train.groupby('question_id').progress_apply(lambda x: Utility.get_answer_by_score(x, 'train_predict_proba')).sum()/df_train.index.nunique()\n",
    "\n",
    "tqdm_pandas(tqdm(total=df_test.index.nunique()))\n",
    "test_score = df_test.groupby('question_id').progress_apply(lambda x: Utility.get_answer_by_score(x, 'test_predict_proba')).sum()/df_test.index.nunique()\n",
    "\n",
    "scores = {'Train': train_score, 'Test': test_score}\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/33767 [00:00<?, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "33768it [02:06, 267.76it/s]                           \n",
      "  0%|          | 0/14471 [00:00<?, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "14472it [00:31, 454.79it/s]                           \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Test': 0.8245456430101582, 'Train': 0.82737584031746969}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = lgb.LGBMClassifier(n_estimators=300, learning_rate=0.1, max_depth=3, min_child_samples=1000, n_jobs=-1)\n",
    "clf.fit(df_train[predictors], df_train[target])\n",
    "\n",
    "df_train['train_predict_proba'] = clf.predict_proba(df_train[predictors])[:, 1]\n",
    "df_test['test_predict_proba'] = clf.predict_proba(df_test[predictors])[:, 1]\n",
    "\n",
    "tqdm_pandas(tqdm(total=df_train.index.nunique()))\n",
    "train_score = df_train.groupby('question_id').progress_apply(lambda x: Utility.get_answer_by_score(x, 'train_predict_proba')).sum()/df_train.index.nunique()\n",
    "\n",
    "tqdm_pandas(tqdm(total=df_test.index.nunique()))\n",
    "test_score = df_test.groupby('question_id').progress_apply(lambda x: Utility.get_answer_by_score(x, 'test_predict_proba')).sum()/df_test.index.nunique()\n",
    "\n",
    "scores = {'Train': train_score, 'Test': test_score}\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
