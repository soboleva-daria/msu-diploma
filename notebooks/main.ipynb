{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import combinations_with_replacement\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "from copy import copy\n",
    "import os\n",
    "import gc\n",
    "\n",
    "#from qa_system import QuestionAnswerSystem\n",
    "from utils import Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/train_task_b.csv')\n",
    "df = df.set_index('question_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем БД"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qa_system = QuestionAnswerSystem()\n",
    "qa_system.create_database(df)\n",
    "qa_system.add_database_to_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Переводим вопрос и ответ в лемматизированную форму"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50364 [00:00<?, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "50365it [01:35, 528.18it/s]                           \n",
      "100%|██████████| 50365/50365 [00:45<00:00, 1115.87it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm_pandas(tqdm(total=df.index.nunique()))\n",
    "df['question_lem'] = df.groupby('question_id').progress_apply(lambda x: Utility.lemmatize_question(x.question.values[0]))\n",
    "df['answer_lem'] = df.groupby('question_id').progress_apply(lambda x: Utility.lemmatize(x.answer.values[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выбираем лучший алгоритм поиска релевантного документа на подвыборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sample = df.sample(frac=0.01, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 504/504 [00:54<00:00,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25F: Accuracy: 0.9761904761904762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Freq: 0.66\n",
    "## Tf-idf: 0.88\n",
    "## Bm25f: 0.9688\n",
    "## MAX_INTERSECT_DOC: 0.76\n",
    "\n",
    "search_rel_question_doc_alg_str = \"BM25F\"\n",
    "qa_system = QuestionAnswerSystem(search_rel_question_doc_alg_str)\n",
    "\n",
    "accuracy = 0\n",
    "errors = {}\n",
    "for question_lem, paragraph_id, question_id in tqdm(df_sample.reset_index()[['question_lem', 'paragraph_id', 'question_id']].values, total=df_sample.question.nunique()):\n",
    "    doc_ids = qa_system.find_rel_question_doc_ids(question_str_lem=question_lem)\n",
    "    if paragraph_id in doc_ids:\n",
    "        accuracy += 1\n",
    "    else:\n",
    "        errors[question_id] = copy(doc_ids)\n",
    "\n",
    "print('{}: Accuracy: {}'.format(search_rel_question_doc_alg_str, accuracy/df_sample.question.nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Для лучшего алгоритма делаем пересчет по всей коллекции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50364it [1:33:29,  8.98it/s]                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25F: Accuracy: 0.9726971267449018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "search_rel_question_doc_alg_str = \"BM25F\"\n",
    "if not os.path.exists(search_rel_question_doc_alg_str):\n",
    "    os.mkdir(search_rel_question_doc_alg_str)\n",
    "qa_system = QuestionAnswerSystem(search_rel_question_doc_alg_str) \n",
    "\n",
    "accuracy = 0\n",
    "errors = {}\n",
    "for question_lem, paragraph_id, question_id in tqdm(df.reset_index()[['question_lem', 'paragraph_id', 'question_id']].values, total=df.question.nunique()):\n",
    "    doc_ids = qa_system.find_rel_question_doc_ids(question_str_lem=question_lem)\n",
    "    if paragraph_id in doc_ids:\n",
    "        accuracy += 1\n",
    "    else:\n",
    "        errors[question_id] = doc_ids\n",
    "    np.save('{}/{}.npy'.format(search_rel_question_doc_alg_str, question_id), doc_ids)\n",
    "np.save('{}_interrogative_pronouns_errors.npy'.format(search_rel_question_doc_alg_str), errors)\n",
    "print('{}: Accuracy: {}'.format(search_rel_question_doc_alg_str, accuracy/df.question.nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формируем датасет для обучения (этап 2)\n",
    "## Не учитываем те вопросы, по которым ошиблись на этапе 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50364/50364 [03:15<00:00, 257.87it/s]\n",
      "  0%|          | 0/2718499 [00:00<?, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "100%|██████████| 2718499/2718499 [2:30:25<00:00, 301.20it/s]  \n"
     ]
    }
   ],
   "source": [
    "search_rel_question_doc_alg_str = 'BM25F'\n",
    "errors = np.load('{}_interrogative_pronouns_errors.npy'.format(search_rel_question_doc_alg_str)).item()\n",
    "train_df = QuestionAnswerSystem.create_train_dataset(errors=errors)\n",
    "\n",
    "tqdm_pandas(tqdm(total=train_df.shape[0]))\n",
    "train_df['sentence_lem'] = train_df.progress_apply(lambda x: Utility.lemmatize(x.sentence), axis=1)\n",
    "train_df.to_pickle('train_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Делаем разметку для классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2718499/2718499 [04:32<00:00, 9986.65it/s] \n"
     ]
    }
   ],
   "source": [
    "train_df = pd.merge(train_df, df.reset_index()[['question_id', 'question', 'question_lem', 'answer', 'answer_lem']], how='left', on='question_id')\n",
    "train_df_with_target = QuestionAnswerSystem.create_target(train_df)\n",
    "train_df_with_target.to_pickle('train_df_with_target.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фильтруем датасет по наличию хотя бы одного предложения с ответом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daria_soboleva/anaconda3/envs/icutestenv/lib/python3.5/site-packages/ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_df_with_target = train_df_with_target.set_index('question_id')\n",
    "train_df_with_target = train_df_with_target[train_df_with_target.groupby('question_id').apply(lambda x: any(x.answer_in_sentence == 1))]\n",
    "train_df_with_target.to_pickle('train_df_with_target_filtered.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Этап 2. Построение классификатора Ans_in_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4% вопросов отсеялись на этапе 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('train_df_with_target_filtered.pkl').reset_index()\n",
    "df.drop_duplicates(subset=['question_id', 'sentence'], keep='first', inplace=True)\n",
    "df = df.set_index('question_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_idxs, test_df_idxs = Utility.train_test_split(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Базовые статистики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/48238 [00:00<?, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "48239it [50:52, 15.80it/s]                             \n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('idfs.pickle', 'rb' ) as f:\n",
    "    idfs = pickle.load(f)\n",
    "with open('idfs_lema.pickle', 'rb' ) as f:\n",
    "    idfs_lem = pickle.load(f)\n",
    "    \n",
    "tqdm_pandas(tqdm(total=df.index.nunique()))\n",
    "base_stats = df.groupby('question_id').progress_apply(lambda x: \n",
    "                                                     QuestionAnswerSystem.get_base_stats(\n",
    "                                                         x.question.values[0],\n",
    "                                                         list(x.sentence),\n",
    "                                                         x.question_lem.values[0],\n",
    "                                                         list(x.sentence_lem)\n",
    "                                                     )).reset_index()\n",
    "base_stats.drop('level_1', axis=1, inplace=True)\n",
    "base_stats.columns = [\n",
    "    'question_id',\n",
    "    'unique_word_count_score',\n",
    "    'unique_lem_word_count_score',\n",
    "    \n",
    "    'unique_word_percent_score',\n",
    "    'unique_lem_word_percent_score',\n",
    "    \n",
    "    'sentence_len',\n",
    "    'sentence_lem_len',\n",
    "    \n",
    "    'bm25f_score',\n",
    "    'bm25f_lem_score',\n",
    "    \n",
    "    'tf_idf_score',\n",
    "    'tf_idf_lem_score',\n",
    "    \n",
    "    'sentence',\n",
    "    'sentence_lem'\n",
    "]\n",
    "base_stats.drop('sentence_lem', inplace=True, axis=1)\n",
    "base_stats.to_pickle('base_stats.pkl')\n",
    "df = pd.merge(df.reset_index(), base_stats, how='left', on=('question_id', 'sentence')).set_index('question_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_stats = pd.read_pickle('base_stats.pkl')\n",
    "base_stats.drop_duplicates(subset=['question_id', 'sentence'], keep='first', inplace=True)\n",
    "df = pd.merge(df.reset_index(), base_stats, how='left', on=('question_id', 'sentence')).set_index('question_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Бейзлайны:\n",
    "* max_unique_word_count_score\n",
    "* max_unique_word_percent_score\n",
    "* max_tf_idf_score\n",
    "* max_bm25f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/33767 [00:00<?, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "33768it [00:21, 1600.23it/s]                           \n",
      "100%|██████████| 33768/33768 [00:20<00:00, 1651.77it/s]\n",
      "100%|██████████| 33768/33768 [00:21<00:00, 1606.59it/s]\n",
      "100%|██████████| 33768/33768 [00:21<00:00, 1591.96it/s]\n",
      "100%|██████████| 33768/33768 [00:20<00:00, 1678.68it/s]\n",
      "100%|██████████| 33768/33768 [00:20<00:00, 1677.31it/s]\n",
      "100%|██████████| 33768/33768 [00:19<00:00, 1720.74it/s]\n",
      "100%|██████████| 33768/33768 [00:20<00:00, 1664.39it/s]\n",
      "  0%|          | 0/14471 [00:00<?, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "14472it [00:08, 1787.35it/s]                           \n",
      "100%|██████████| 14472/14472 [00:08<00:00, 1652.58it/s]\n",
      "100%|██████████| 14472/14472 [00:09<00:00, 1563.70it/s]\n",
      "100%|██████████| 14472/14472 [00:08<00:00, 1711.18it/s]\n",
      "100%|██████████| 14472/14472 [00:08<00:00, 1695.85it/s]\n",
      "100%|██████████| 14472/14472 [00:08<00:00, 1635.30it/s]\n",
      "100%|██████████| 14472/14472 [00:08<00:00, 1739.08it/s]\n",
      "100%|██████████| 14472/14472 [00:08<00:00, 1671.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bm25f_lem_score</th>\n",
       "      <th>bm25f_score</th>\n",
       "      <th>tf_idf_lem_score</th>\n",
       "      <th>tf_idf_score</th>\n",
       "      <th>unique_lem_word_count_score</th>\n",
       "      <th>unique_lem_word_percent_score</th>\n",
       "      <th>unique_word_count_score</th>\n",
       "      <th>unique_word_percent_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.937166</td>\n",
       "      <td>0.920760</td>\n",
       "      <td>0.932218</td>\n",
       "      <td>0.921084</td>\n",
       "      <td>0.940105</td>\n",
       "      <td>0.940105</td>\n",
       "      <td>0.928041</td>\n",
       "      <td>0.928041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>0.938901</td>\n",
       "      <td>0.922034</td>\n",
       "      <td>0.933665</td>\n",
       "      <td>0.922082</td>\n",
       "      <td>0.941904</td>\n",
       "      <td>0.941904</td>\n",
       "      <td>0.929850</td>\n",
       "      <td>0.929850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bm25f_lem_score  bm25f_score  tf_idf_lem_score  tf_idf_score  \\\n",
       "Test          0.937166     0.920760          0.932218      0.921084   \n",
       "Train         0.938901     0.922034          0.933665      0.922082   \n",
       "\n",
       "       unique_lem_word_count_score  unique_lem_word_percent_score  \\\n",
       "Test                      0.940105                       0.940105   \n",
       "Train                     0.941904                       0.941904   \n",
       "\n",
       "       unique_word_count_score  unique_word_percent_score  \n",
       "Test                  0.928041                   0.928041  \n",
       "Train                 0.929850                   0.929850  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_scores(df, columns):\n",
    "    n_questions = df.index.nunique()\n",
    "    scores = {}\n",
    "    tqdm_pandas(tqdm(total=n_questions))\n",
    "    for col in columns:\n",
    "        scores[col] = df.groupby('question_id').progress_apply(lambda x: Utility.get_answer_by_score(x, col)).sum()/n_questions\n",
    "    return scores\n",
    "\n",
    "train_scores = get_scores(df.loc[train_df_idxs], base_stats.columns.difference(['question_id', 'sentence_len', 'sentence_lem_len', 'sentence']))\n",
    "test_scores = get_scores(df.loc[test_df_idxs], base_stats.columns.difference(['question_id', 'sentence_len', 'sentence_lem_len', 'sentence']))\n",
    "\n",
    "scores = {'Train': {}, 'Test': {}}\n",
    "scores['Train'] = train_scores\n",
    "scores['Test'] = test_scores\n",
    "pd.DataFrame(scores).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лог-регрессия на базовых фичах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/33767 [00:00<?, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "33768it [00:17, 1888.78it/s]                           \n",
      "  0%|          | 0/14471 [00:00<?, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "14472it [00:08, 1728.32it/s]                           \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Test': 0.9686258282162566, 'Train': 0.9698701282366897}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'answer_in_sentence'\n",
    "predictors = df.columns.difference([\n",
    "    'sentence',\n",
    "    'sentence_lem',\n",
    "    'question',\n",
    "    'question_lem',\n",
    "    'answer',\n",
    "    'answer_lem',\n",
    "    target\n",
    "])\n",
    "df_train = df.loc[train_df_idxs].copy()\n",
    "df_test = df.loc[test_df_idxs].copy()\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(df_train[predictors])\n",
    "X_test_sc = sc.transform(df_test[predictors])\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_sc, df_train[target])\n",
    "\n",
    "df_train['train_predict_proba'] = clf.predict_proba(X_train_sc)[:, 1]\n",
    "df_test['test_predict_proba'] = clf.predict_proba(X_test_sc)[:, 1]\n",
    "\n",
    "tqdm_pandas(tqdm(total=df_train.index.nunique()))\n",
    "train_score = df_train.groupby('question_id').progress_apply(lambda x: Utility.get_answer_by_score(x, 'train_predict_proba')).sum()/df_train.index.nunique()\n",
    "\n",
    "tqdm_pandas(tqdm(total=df_test.index.nunique()))\n",
    "test_score = df_test.groupby('question_id').progress_apply(lambda x: Utility.get_answer_by_score(x, 'test_predict_proba')).sum()/df_test.index.nunique()\n",
    "\n",
    "scores = {'Train': train_score, 'Test': test_score}\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/33767 [00:00<?, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "33768it [00:51, 654.10it/s]                           \n",
      "  0%|          | 0/14471 [00:00<?, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "14472it [00:24, 585.89it/s]                           \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Test': 0.8253748877064474, 'Train': 0.82802736399443244}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Метрика (accuracy по вопросам)\n",
    "clf = lgb.LGBMClassifier(n_estimators=300, learning_rate=0.1, max_depth=3, min_child_samples=1000, n_jobs=-1)\n",
    "clf.fit(df_train[predictors], df_train[target])\n",
    "\n",
    "df_train['train_predict_proba'] = clf.predict_proba(df_train[predictors])[:, 1]\n",
    "df_test['test_predict_proba'] = clf.predict_proba(df_test[predictors])[:, 1]\n",
    "\n",
    "tqdm_pandas(tqdm(total=df_train.index.nunique()))\n",
    "train_score = df_train.groupby('question_id').progress_apply(lambda x: Utility.get_answer_by_score(x, 'train_predict_proba')).sum()/df_train.index.nunique()\n",
    "\n",
    "tqdm_pandas(tqdm(total=df_test.index.nunique()))\n",
    "test_score = df_test.groupby('question_id').progress_apply(lambda x: Utility.get_answer_by_score(x, 'test_predict_proba')).sum()/df_test.index.nunique()\n",
    "\n",
    "scores = {'Train': train_score, 'Test': test_score}\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Интеракшенсы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип вопроса start...(2646917, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48238/48238 [02:38<00:00, 303.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Неры предложений start...(2646917, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48238/48238 [42:36<00:00, 18.87it/s]\n",
      "  0%|          | 0/2646917 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Индикаторы неров в предложениях start...(2646917, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "2646918it [05:00, 8813.75it/s]                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Статистики start...(2646917, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3698 [00:00<?, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "3699it [00:11, 313.08it/s]                          \n",
      "  0%|          | 0/3698 [00:00<?, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "  2%|▏         | 61/3698 [00:00<00:06, 605.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Типовой нер start...(2646917, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3699it [00:07, 493.24it/s]                           \n",
      "  0%|          | 0/48238 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пересечение start...(2646917, 27)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "48239it [01:05, 731.80it/s]                            \n",
      "  0%|          | 0/48238 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Интеракшенсы start...(2646917, 27)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "48239it [02:01, 396.94it/s]                           \n"
     ]
    }
   ],
   "source": [
    "# Тип вопроса\n",
    "print('Тип вопроса start...{}'.format(df.shape))\n",
    "df = Utility.applyParallel(df.groupby('question_id'), func=Utility.get_question_type)\n",
    "\n",
    "# Неры предложений\n",
    "print('Неры предложений start...{}'.format(df.shape))\n",
    "res = Utility.applyParallel(df.reset_index().groupby('question_id'), func=Utility.get_sentence_ners)\n",
    "res.columns = ['question_id', 'sentence', 'sentence_ners']\n",
    "#res = pd.read_pickle('df_with_target_stat.pkl')[['question_id', 'sentence', 'sentence_ners']]\n",
    "df = pd.merge(df.reset_index(), res, how='left', on=('question_id', 'sentence')).set_index('question_id')\n",
    "\n",
    "# Индикаторы неров в предложениях\n",
    "ners = ['Per', 'Geox', 'Orgn', 'Date', 'Num']\n",
    "print('Индикаторы неров в предложениях start...{}'.format(df.shape))\n",
    "for ner in ners:\n",
    "    df[ner] = 0    \n",
    "tqdm_pandas(tqdm(total=df.shape[0]))\n",
    "df = df.progress_apply(lambda x: Utility.get_sentence_ners_indicators(x), axis=1)\n",
    "\n",
    "# Статистику по таргету считаем только по трейну\n",
    "print('Статистики start...{}'.format(df.shape))\n",
    "df_right = df.loc[train_df_idxs]\n",
    "df_right = df_right[df_right.answer_in_sentence == 1]\n",
    "\n",
    "# Частоты всречаемости типов вопросов (фильтруем)\n",
    "freqs = df_right.question_type.value_counts().reset_index()\n",
    "freqs.columns = ['question_type', 'freq']\n",
    "df_right = pd.merge(df_right, freqs, how='left', on='question_type')\n",
    "df_right = df_right[df_right.freq > 1]\n",
    "\n",
    "# global: сколько раз нер встретился в ответах на все типы вопросов\n",
    "for ner in ners:\n",
    "    df_right['{}_global'.format(ner)] = df_right[ner].sum() \n",
    "    \n",
    "# local: сколько раз нер встретился в ответ на данный типа вопрос\n",
    "tqdm_pandas(tqdm(total=df_right.question_type.nunique()))\n",
    "df_right = df_right.groupby('question_type').progress_apply(lambda x: Utility.get_ners_counts_by_question_type(x, ners))\n",
    "   \n",
    "# Нормируем\n",
    "for ner in ners:\n",
    "    df_right['{}_local'.format(ner)] /= df_right['{}_global'.format(ner)].sum()\n",
    "    \n",
    "# Определяем самый типовой нер для данного типа вопроса\n",
    "print('Типовой нер start...{}'.format(df.shape))\n",
    "tqdm_pandas(tqdm(total=df_right.question_type.nunique()))\n",
    "df_right = df_right.groupby('question_type').progress_apply(lambda x: Utility.get_most_freq_ner_question_type(x, ners))\n",
    "\n",
    "# Вставляем в исходный датасет фичу\n",
    "df = pd.merge(df.reset_index(), df_right[['question_type', 'question_type_ner', 'freq']].drop_duplicates(), how='left', on='question_type').set_index('question_id')\n",
    "\n",
    "# Индикатор пересечения неров из предложения и вопроса\n",
    "print('Пересечение start...{}'.format(df.shape))\n",
    "tqdm_pandas(tqdm(total=df.index.nunique()))\n",
    "res = df.reset_index().groupby('question_id').progress_apply(lambda x: Utility.get_sentence_ner_question_type_indicator(x))\n",
    "res.columns = ['question_id', 'sentence', 'question_type_ner_in_sentence_ners']\n",
    "res = res.set_index(['question_id', 'sentence'])\n",
    "\n",
    "# Интеракшенсы: дали такие же качество\n",
    "print('Интеракшенсы start...{}'.format(df.shape))\n",
    "tqdm_pandas(tqdm(total=df.index.nunique()))\n",
    "combs = list(combinations_with_replacement(['Per', 'Geox', 'Orgn', 'Date', 'Num'], r=2))\n",
    "res1 = df.reset_index().groupby('question_id').progress_apply(lambda x: Utility.get_sentence_ner_question_type_interactions(x, combs))\n",
    "res1.columns = ['question_id', 'sentence'] + ['{}_{}'.format(comb[0], comb[1]) for comb in combs]\n",
    "res1 = res1.set_index(['question_id', 'sentence'])\n",
    "\n",
    "df = df.reset_index().set_index(['question_id', 'sentence'])\n",
    "df['question_type_ner_in_sentence_ners'] = res.question_type_ner_in_sentence_ners\n",
    "\n",
    "for col in ['{}_{}'.format(comb[0], comb[1]) for comb in combs]:\n",
    "    df[col] = res1[col]\n",
    "    \n",
    "df = df.reset_index().set_index('question_id')\n",
    "df.to_pickle('one_stable_version_with_interactions.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/33767 [00:00<?, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "33768it [00:20, 1636.70it/s]                           \n",
      "  0%|          | 0/14471 [00:00<?, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "14472it [00:08, 1644.52it/s]                           \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Test': 0.9690714166976677, 'Train': 0.9712376105986555}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'answer_in_sentence'\n",
    "predictors = df.columns.difference([\n",
    "    'sentence',\n",
    "    'sentence_lem',\n",
    "    'question',\n",
    "    'question_lem',\n",
    "    'answer',\n",
    "    'answer_lem',\n",
    "    'question_type',\n",
    "    'sentence_ners',\n",
    "    'Per', 'Geox', 'Orgn', 'Date', 'Num',\n",
    "    'question_type_ner',\n",
    "    'freq',\n",
    "\n",
    "'Date_Date', 'Date_Num', 'Geox_Date', 'Geox_Geox', 'Geox_Num',\n",
    "       'Geox_Orgn', 'Num_Num', 'Orgn_Date', 'Orgn_Num', 'Orgn_Orgn',\n",
    "       'Per_Date', 'Per_Geox', 'Per_Num', 'Per_Orgn', 'Per_Per',\n",
    "    target\n",
    "])\n",
    "df_train = df.loc[train_df_idxs].copy()\n",
    "df_test = df.loc[test_df_idxs].copy()\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(df_train[predictors])\n",
    "X_test_sc = sc.transform(df_test[predictors])\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_sc, df_train[target])\n",
    "\n",
    "df_train['train_predict_proba'] = clf.predict_proba(X_train_sc)[:, 1]\n",
    "df_test['test_predict_proba'] = clf.predict_proba(X_test_sc)[:, 1]\n",
    "\n",
    "tqdm_pandas(tqdm(total=df_train.index.nunique()))\n",
    "train_score = df_train.groupby('question_id').progress_apply(lambda x: Utility.get_answer_by_score(x, 'train_predict_proba')).sum()/df_train.index.nunique()\n",
    "\n",
    "tqdm_pandas(tqdm(total=df_test.index.nunique()))\n",
    "test_score = df_test.groupby('question_id').progress_apply(lambda x: Utility.get_answer_by_score(x, 'test_predict_proba')).sum()/df_test.index.nunique()\n",
    "\n",
    "scores = {'Train': train_score, 'Test': test_score}\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('one_stable_version_with_interactions.pkl')\n",
    "train_df_idxs, test_df_idxs = Utility.train_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-03-18 18:21:42--  http://rusvectores.org/static/models/rusvectores4/ruwikiruscorpora/ruwikiruscorpora_upos_skipgram_300_2_2018.vec.gz\n",
      "Resolving rusvectores.org (rusvectores.org)... 176.195.17.217\n",
      "Connecting to rusvectores.org (rusvectores.org)|176.195.17.217|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 394697055 (376M) [application/x-gzip]\n",
      "Saving to: ‘ruwikiruscorpora_upos_skipgram_300_2_2018.vec.gz’\n",
      "\n",
      "ruwikiruscorpora_up 100%[===================>] 376.41M  5.56MB/s    in 60s     \n",
      "\n",
      "2018-03-18 18:22:41 (6.32 MB/s) - ‘ruwikiruscorpora_upos_skipgram_300_2_2018.vec.gz’ saved [394697055/394697055]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 300 -- размерность вектора\n",
    "# 5 -- размерность окна\n",
    "!wget http://rusvectores.org/static/models/rusvectores4/ruwikiruscorpora/ruwikiruscorpora_upos_skipgram_300_2_2018.vec.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2646917 [00:00<?, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "  0%|          | 103/2646917 [00:15<3431:02:16,  4.67s/it]/home/zeus/miniconda3/envs/ipykernel_py3/lib/python3.6/site-packages/scipy/spatial/distance.py:644: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "2646918it [41:52, 1053.67it/s]                              \n"
     ]
    }
   ],
   "source": [
    "#df = df.reset_index()\n",
    "#df = Utility.applyParallel(df.groupby(df.index), func=Utility.get_question_sentence_word2vec_cosine_dist)\n",
    "tqdm_pandas(tqdm(total=df.shape[0]))\n",
    "df = df.progress_apply(lambda x: Utility.get_question_sentence_word2vec_cosine_dist(x), axis=1)\n",
    "df.question_sentence_word2vec_cosine_dist.fillna(-1, inplace=True)\n",
    "\n",
    "## Test: 0.9279097264237055, Train: 0.9105578792069107 (одиночный)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/33767 [00:00<?, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "33768it [00:19, 1744.30it/s]                           \n",
      "  0%|          | 0/14471 [00:00<?, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n",
      "14472it [00:08, 1740.97it/s]                           \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Test': 0.9690994824114406, 'Train': 0.9712612797432139}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'answer_in_sentence'\n",
    "predictors = df.columns.difference([\n",
    "    'sentence',\n",
    "    'sentence_lem',\n",
    "    'question',\n",
    "    'question_lem',\n",
    "    'answer',\n",
    "    'answer_lem',\n",
    "    'question_type',\n",
    "    'sentence_ners',\n",
    "    'Per', 'Geox', 'Orgn', 'Date', 'Num',\n",
    "    'question_type_ner',\n",
    "    'freq',\n",
    "'Date_Date', 'Date_Num', 'Geox_Date', 'Geox_Geox', 'Geox_Num',\n",
    "       'Geox_Orgn', 'Num_Num', 'Orgn_Date', 'Orgn_Num', 'Orgn_Orgn',\n",
    "       'Per_Date', 'Per_Geox', 'Per_Num', 'Per_Orgn', 'Per_Per',\n",
    "\n",
    "    target\n",
    "])\n",
    "df_train = df.loc[train_df_idxs].copy()\n",
    "df_test = df.loc[test_df_idxs].copy()\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(df_train[predictors])\n",
    "X_test_sc = sc.transform(df_test[predictors])\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_sc, df_train[target])\n",
    "\n",
    "df_train['train_predict_proba'] = clf.predict_proba(X_train_sc)[:, 1]\n",
    "df_test['test_predict_proba'] = clf.predict_proba(X_test_sc)[:, 1]\n",
    "\n",
    "tqdm_pandas(tqdm(total=df_train.index.nunique()))\n",
    "train_score = df_train.groupby('question_id').progress_apply(lambda x: Utility.get_answer_by_score(x, 'train_predict_proba')).sum()/df_train.index.nunique()\n",
    "\n",
    "tqdm_pandas(tqdm(total=df_test.index.nunique()))\n",
    "test_score = df_test.groupby('question_id').progress_apply(lambda x: Utility.get_answer_by_score(x, 'test_predict_proba')).sum()/df_test.index.nunique()\n",
    "\n",
    "scores = {'Train': train_score, 'Test': test_score}\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bm25f_lem_score', 'bm25f_score', 'doc_number',\n",
       "       'question_sentence_word2vec_cosine_dist',\n",
       "       'question_type_ner_in_sentence_ners', 'sentence_lem_len',\n",
       "       'sentence_len', 'tf_idf_lem_score', 'tf_idf_score',\n",
       "       'unique_lem_word_count_score', 'unique_lem_word_percent_score',\n",
       "       'unique_word_count_score', 'unique_word_percent_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TopicModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
